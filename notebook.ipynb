{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "import category_encoders as ce\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>track_id</th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>...</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5SuOikwiRyPMVoIQDJUgSV</td>\n",
       "      <td>Gen Hoshino</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>73</td>\n",
       "      <td>230666</td>\n",
       "      <td>False</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.4610</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.3580</td>\n",
       "      <td>0.715</td>\n",
       "      <td>87.917</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4qPNDBW1i3p13qLCt0Ki3A</td>\n",
       "      <td>Ben Woodward</td>\n",
       "      <td>Ghost (Acoustic)</td>\n",
       "      <td>Ghost - Acoustic</td>\n",
       "      <td>55</td>\n",
       "      <td>149610</td>\n",
       "      <td>False</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.235</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.267</td>\n",
       "      <td>77.489</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1iJBSr7s7jYXzM8EGcbK5b</td>\n",
       "      <td>Ingrid Michaelson;ZAYN</td>\n",
       "      <td>To Begin Again</td>\n",
       "      <td>To Begin Again</td>\n",
       "      <td>57</td>\n",
       "      <td>210826</td>\n",
       "      <td>False</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.734</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.120</td>\n",
       "      <td>76.332</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6lfxq3CG4xtTiEg7opyCyx</td>\n",
       "      <td>Kina Grannis</td>\n",
       "      <td>Crazy Rich Asians (Original Motion Picture Sou...</td>\n",
       "      <td>Can't Help Falling In Love</td>\n",
       "      <td>71</td>\n",
       "      <td>201933</td>\n",
       "      <td>False</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.515</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.143</td>\n",
       "      <td>181.740</td>\n",
       "      <td>3</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5vjLSffimiIP26QG5WcN2K</td>\n",
       "      <td>Chord Overstreet</td>\n",
       "      <td>Hold On</td>\n",
       "      <td>Hold On</td>\n",
       "      <td>82</td>\n",
       "      <td>198853</td>\n",
       "      <td>False</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.681</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.167</td>\n",
       "      <td>119.949</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                track_id                 artists  \\\n",
       "0           0  5SuOikwiRyPMVoIQDJUgSV             Gen Hoshino   \n",
       "1           1  4qPNDBW1i3p13qLCt0Ki3A            Ben Woodward   \n",
       "2           2  1iJBSr7s7jYXzM8EGcbK5b  Ingrid Michaelson;ZAYN   \n",
       "3           3  6lfxq3CG4xtTiEg7opyCyx            Kina Grannis   \n",
       "4           4  5vjLSffimiIP26QG5WcN2K        Chord Overstreet   \n",
       "\n",
       "                                          album_name  \\\n",
       "0                                             Comedy   \n",
       "1                                   Ghost (Acoustic)   \n",
       "2                                     To Begin Again   \n",
       "3  Crazy Rich Asians (Original Motion Picture Sou...   \n",
       "4                                            Hold On   \n",
       "\n",
       "                   track_name  popularity  duration_ms  explicit  \\\n",
       "0                      Comedy          73       230666     False   \n",
       "1            Ghost - Acoustic          55       149610     False   \n",
       "2              To Begin Again          57       210826     False   \n",
       "3  Can't Help Falling In Love          71       201933     False   \n",
       "4                     Hold On          82       198853     False   \n",
       "\n",
       "   danceability  energy  ...  loudness  mode  speechiness  acousticness  \\\n",
       "0         0.676  0.4610  ...    -6.746     0       0.1430        0.0322   \n",
       "1         0.420  0.1660  ...   -17.235     1       0.0763        0.9240   \n",
       "2         0.438  0.3590  ...    -9.734     1       0.0557        0.2100   \n",
       "3         0.266  0.0596  ...   -18.515     1       0.0363        0.9050   \n",
       "4         0.618  0.4430  ...    -9.681     1       0.0526        0.4690   \n",
       "\n",
       "   instrumentalness  liveness  valence    tempo  time_signature  track_genre  \n",
       "0          0.000001    0.3580    0.715   87.917               4     acoustic  \n",
       "1          0.000006    0.1010    0.267   77.489               4     acoustic  \n",
       "2          0.000000    0.1170    0.120   76.332               4     acoustic  \n",
       "3          0.000071    0.1320    0.143  181.740               3     acoustic  \n",
       "4          0.000000    0.0829    0.167  119.949               4     acoustic  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset = pd.read_csv('dataset/spotify_tracks.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.isnull().sum() # to check if there are missing values\n",
    "\n",
    "# drop records with missing values\n",
    "dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0          113999\n",
       "track_id             89740\n",
       "artists              31437\n",
       "album_name           46589\n",
       "track_name           73608\n",
       "popularity             101\n",
       "duration_ms          50696\n",
       "explicit                 2\n",
       "danceability          1174\n",
       "energy                2083\n",
       "key                     12\n",
       "loudness             19480\n",
       "mode                     2\n",
       "speechiness           1489\n",
       "acousticness          5061\n",
       "instrumentalness      5346\n",
       "liveness              1722\n",
       "valence               1790\n",
       "tempo                45652\n",
       "time_signature           5\n",
       "track_genre            114\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.nunique(axis=0) # to check the number of distinct values for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(columns=['Unnamed: 0', 'track_id', 'popularity'])  # features\n",
    "y = dataset['popularity']                                           # target variable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature encoding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***explicit*** is a binary categorical feature that we map it in {0,1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['explicit'] = X['explicit'].map({False : 0, True : 1})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***key*** and ***time_signature*** are categorical features with a restricted number of distinct values on which we apply one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = ce.OneHotEncoder(cols=['key','time_signature']) \n",
    "X = ohe.fit_transform(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***artists***, ***album_name***, ***track_name*** and ***track_genre*** are categorical features with a large number of distinct values on which we apply binary encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "be = ce.BinaryEncoder(cols=['artists', 'album_name', 'track_name', 'track_genre'])\n",
    "X = be.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((113999, 84),\n",
       " Index(['artists_0', 'artists_1', 'artists_2', 'artists_3', 'artists_4',\n",
       "        'artists_5', 'artists_6', 'artists_7', 'artists_8', 'artists_9',\n",
       "        'artists_10', 'artists_11', 'artists_12', 'artists_13', 'artists_14',\n",
       "        'album_name_0', 'album_name_1', 'album_name_2', 'album_name_3',\n",
       "        'album_name_4', 'album_name_5', 'album_name_6', 'album_name_7',\n",
       "        'album_name_8', 'album_name_9', 'album_name_10', 'album_name_11',\n",
       "        'album_name_12', 'album_name_13', 'album_name_14', 'album_name_15',\n",
       "        'track_name_0', 'track_name_1', 'track_name_2', 'track_name_3',\n",
       "        'track_name_4', 'track_name_5', 'track_name_6', 'track_name_7',\n",
       "        'track_name_8', 'track_name_9', 'track_name_10', 'track_name_11',\n",
       "        'track_name_12', 'track_name_13', 'track_name_14', 'track_name_15',\n",
       "        'track_name_16', 'duration_ms', 'explicit', 'danceability', 'energy',\n",
       "        'key_1', 'key_2', 'key_3', 'key_4', 'key_5', 'key_6', 'key_7', 'key_8',\n",
       "        'key_9', 'key_10', 'key_11', 'key_12', 'loudness', 'mode',\n",
       "        'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n",
       "        'valence', 'tempo', 'time_signature_1', 'time_signature_2',\n",
       "        'time_signature_3', 'time_signature_4', 'time_signature_5',\n",
       "        'track_genre_0', 'track_genre_1', 'track_genre_2', 'track_genre_3',\n",
       "        'track_genre_4', 'track_genre_5', 'track_genre_6'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split data in training and test set and we standardize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True) #stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = preprocessing.StandardScaler().set_output(transform=\"pandas\")\n",
    "\n",
    "X_train = standard_scaler.fit_transform(X_train)\n",
    "X_test = standard_scaler.transform(X_test)\n",
    "\n",
    "# should I standardize also the target variable? boh, I don't think it's mandatory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider also the data corresponding only to numerical features of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['duration_ms', 'explicit', 'danceability', 'energy', 'loudness', 'mode',\n",
    "                      'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "\n",
    "X_train_numerical = X_train[numerical_features]\n",
    "X_test_numerical = X_test[numerical_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96253</th>\n",
       "      <td>1.209605</td>\n",
       "      <td>-0.306913</td>\n",
       "      <td>0.427460</td>\n",
       "      <td>0.950305</td>\n",
       "      <td>0.370570</td>\n",
       "      <td>-1.326874</td>\n",
       "      <td>-0.230378</td>\n",
       "      <td>-0.494867</td>\n",
       "      <td>-0.503032</td>\n",
       "      <td>2.086197</td>\n",
       "      <td>-0.196163</td>\n",
       "      <td>-0.971364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70417</th>\n",
       "      <td>0.032251</td>\n",
       "      <td>-0.306913</td>\n",
       "      <td>0.583241</td>\n",
       "      <td>-1.112037</td>\n",
       "      <td>-0.285686</td>\n",
       "      <td>-1.326874</td>\n",
       "      <td>-0.467827</td>\n",
       "      <td>1.441588</td>\n",
       "      <td>-0.505483</td>\n",
       "      <td>0.171212</td>\n",
       "      <td>-0.161413</td>\n",
       "      <td>-1.607835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66688</th>\n",
       "      <td>-1.199902</td>\n",
       "      <td>-0.306913</td>\n",
       "      <td>1.264062</td>\n",
       "      <td>-1.652458</td>\n",
       "      <td>-1.635483</td>\n",
       "      <td>0.753651</td>\n",
       "      <td>4.618883</td>\n",
       "      <td>1.092785</td>\n",
       "      <td>-0.505483</td>\n",
       "      <td>-0.064882</td>\n",
       "      <td>0.711186</td>\n",
       "      <td>-0.402106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51391</th>\n",
       "      <td>0.038294</td>\n",
       "      <td>-0.306913</td>\n",
       "      <td>0.819797</td>\n",
       "      <td>0.747647</td>\n",
       "      <td>0.486391</td>\n",
       "      <td>0.753651</td>\n",
       "      <td>1.515962</td>\n",
       "      <td>-0.739028</td>\n",
       "      <td>-0.505483</td>\n",
       "      <td>1.823870</td>\n",
       "      <td>0.695742</td>\n",
       "      <td>0.528133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95123</th>\n",
       "      <td>1.224293</td>\n",
       "      <td>-0.306913</td>\n",
       "      <td>1.264062</td>\n",
       "      <td>0.242990</td>\n",
       "      <td>0.302941</td>\n",
       "      <td>0.753651</td>\n",
       "      <td>-0.370388</td>\n",
       "      <td>0.587623</td>\n",
       "      <td>-0.505483</td>\n",
       "      <td>-0.489851</td>\n",
       "      <td>0.857906</td>\n",
       "      <td>-0.603445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76821</th>\n",
       "      <td>0.097276</td>\n",
       "      <td>-0.306913</td>\n",
       "      <td>-0.374524</td>\n",
       "      <td>-1.791537</td>\n",
       "      <td>-0.736874</td>\n",
       "      <td>0.753651</td>\n",
       "      <td>-0.458367</td>\n",
       "      <td>1.817453</td>\n",
       "      <td>2.257574</td>\n",
       "      <td>-0.679775</td>\n",
       "      <td>-1.250232</td>\n",
       "      <td>0.321024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110269</th>\n",
       "      <td>0.759202</td>\n",
       "      <td>-0.306913</td>\n",
       "      <td>-0.045653</td>\n",
       "      <td>1.125147</td>\n",
       "      <td>0.645051</td>\n",
       "      <td>0.753651</td>\n",
       "      <td>-0.164157</td>\n",
       "      <td>-0.917339</td>\n",
       "      <td>2.341303</td>\n",
       "      <td>3.413570</td>\n",
       "      <td>-1.312009</td>\n",
       "      <td>0.763428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103695</th>\n",
       "      <td>-0.848953</td>\n",
       "      <td>-0.306913</td>\n",
       "      <td>0.358224</td>\n",
       "      <td>-0.321274</td>\n",
       "      <td>-0.631762</td>\n",
       "      <td>-1.326874</td>\n",
       "      <td>-0.307005</td>\n",
       "      <td>0.840204</td>\n",
       "      <td>-0.505483</td>\n",
       "      <td>-0.164566</td>\n",
       "      <td>1.568341</td>\n",
       "      <td>-0.107604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>-0.103603</td>\n",
       "      <td>-0.306913</td>\n",
       "      <td>-0.841867</td>\n",
       "      <td>-2.121352</td>\n",
       "      <td>-1.372703</td>\n",
       "      <td>0.753651</td>\n",
       "      <td>-0.484855</td>\n",
       "      <td>1.901646</td>\n",
       "      <td>-0.505483</td>\n",
       "      <td>-0.657215</td>\n",
       "      <td>-1.373786</td>\n",
       "      <td>-0.597174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>-0.933229</td>\n",
       "      <td>-0.306913</td>\n",
       "      <td>-0.011035</td>\n",
       "      <td>-1.592852</td>\n",
       "      <td>-2.064260</td>\n",
       "      <td>0.753651</td>\n",
       "      <td>-0.386470</td>\n",
       "      <td>1.850529</td>\n",
       "      <td>2.431473</td>\n",
       "      <td>0.869001</td>\n",
       "      <td>-1.510081</td>\n",
       "      <td>-0.239862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91199 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        duration_ms  explicit  danceability    energy  loudness      mode  \\\n",
       "96253      1.209605 -0.306913      0.427460  0.950305  0.370570 -1.326874   \n",
       "70417      0.032251 -0.306913      0.583241 -1.112037 -0.285686 -1.326874   \n",
       "66688     -1.199902 -0.306913      1.264062 -1.652458 -1.635483  0.753651   \n",
       "51391      0.038294 -0.306913      0.819797  0.747647  0.486391  0.753651   \n",
       "95123      1.224293 -0.306913      1.264062  0.242990  0.302941  0.753651   \n",
       "...             ...       ...           ...       ...       ...       ...   \n",
       "76821      0.097276 -0.306913     -0.374524 -1.791537 -0.736874  0.753651   \n",
       "110269     0.759202 -0.306913     -0.045653  1.125147  0.645051  0.753651   \n",
       "103695    -0.848953 -0.306913      0.358224 -0.321274 -0.631762 -1.326874   \n",
       "860       -0.103603 -0.306913     -0.841867 -2.121352 -1.372703  0.753651   \n",
       "15795     -0.933229 -0.306913     -0.011035 -1.592852 -2.064260  0.753651   \n",
       "\n",
       "        speechiness  acousticness  instrumentalness  liveness   valence  \\\n",
       "96253     -0.230378     -0.494867         -0.503032  2.086197 -0.196163   \n",
       "70417     -0.467827      1.441588         -0.505483  0.171212 -0.161413   \n",
       "66688      4.618883      1.092785         -0.505483 -0.064882  0.711186   \n",
       "51391      1.515962     -0.739028         -0.505483  1.823870  0.695742   \n",
       "95123     -0.370388      0.587623         -0.505483 -0.489851  0.857906   \n",
       "...             ...           ...               ...       ...       ...   \n",
       "76821     -0.458367      1.817453          2.257574 -0.679775 -1.250232   \n",
       "110269    -0.164157     -0.917339          2.341303  3.413570 -1.312009   \n",
       "103695    -0.307005      0.840204         -0.505483 -0.164566  1.568341   \n",
       "860       -0.484855      1.901646         -0.505483 -0.657215 -1.373786   \n",
       "15795     -0.386470      1.850529          2.431473  0.869001 -1.510081   \n",
       "\n",
       "           tempo  \n",
       "96253  -0.971364  \n",
       "70417  -1.607835  \n",
       "66688  -0.402106  \n",
       "51391   0.528133  \n",
       "95123  -0.603445  \n",
       "...          ...  \n",
       "76821   0.321024  \n",
       "110269  0.763428  \n",
       "103695 -0.107604  \n",
       "860    -0.597174  \n",
       "15795  -0.239862  \n",
       "\n",
       "[91199 rows x 12 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113186</th>\n",
       "      <td>1.964016</td>\n",
       "      <td>-0.306913</td>\n",
       "      <td>-1.141890</td>\n",
       "      <td>-0.170274</td>\n",
       "      <td>0.254946</td>\n",
       "      <td>0.753651</td>\n",
       "      <td>-0.514181</td>\n",
       "      <td>-0.933546</td>\n",
       "      <td>-0.505483</td>\n",
       "      <td>-0.196045</td>\n",
       "      <td>-1.649465</td>\n",
       "      <td>0.863697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42819</th>\n",
       "      <td>-1.241114</td>\n",
       "      <td>-0.306913</td>\n",
       "      <td>-2.284284</td>\n",
       "      <td>1.415226</td>\n",
       "      <td>0.928853</td>\n",
       "      <td>0.753651</td>\n",
       "      <td>0.314526</td>\n",
       "      <td>-0.933245</td>\n",
       "      <td>2.074015</td>\n",
       "      <td>1.084109</td>\n",
       "      <td>-1.715876</td>\n",
       "      <td>0.003406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59311</th>\n",
       "      <td>-0.133802</td>\n",
       "      <td>-0.306913</td>\n",
       "      <td>-2.272745</td>\n",
       "      <td>0.644332</td>\n",
       "      <td>-0.357281</td>\n",
       "      <td>-1.326874</td>\n",
       "      <td>0.560489</td>\n",
       "      <td>0.894329</td>\n",
       "      <td>-0.499332</td>\n",
       "      <td>-0.096361</td>\n",
       "      <td>-1.486915</td>\n",
       "      <td>-1.552964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90417</th>\n",
       "      <td>-0.752701</td>\n",
       "      <td>-0.306913</td>\n",
       "      <td>-0.853406</td>\n",
       "      <td>-1.028589</td>\n",
       "      <td>-1.025040</td>\n",
       "      <td>0.753651</td>\n",
       "      <td>-0.497153</td>\n",
       "      <td>0.013302</td>\n",
       "      <td>-0.505483</td>\n",
       "      <td>-0.563302</td>\n",
       "      <td>-0.045582</td>\n",
       "      <td>-1.265400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61000</th>\n",
       "      <td>0.076425</td>\n",
       "      <td>-0.306913</td>\n",
       "      <td>-0.068731</td>\n",
       "      <td>1.192700</td>\n",
       "      <td>0.986764</td>\n",
       "      <td>-1.326874</td>\n",
       "      <td>-0.346737</td>\n",
       "      <td>0.506437</td>\n",
       "      <td>-0.505483</td>\n",
       "      <td>0.276143</td>\n",
       "      <td>1.309650</td>\n",
       "      <td>-0.988476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83384</th>\n",
       "      <td>-0.132516</td>\n",
       "      <td>-0.306913</td>\n",
       "      <td>1.056354</td>\n",
       "      <td>-0.225905</td>\n",
       "      <td>-0.195250</td>\n",
       "      <td>0.753651</td>\n",
       "      <td>-0.486747</td>\n",
       "      <td>-0.902003</td>\n",
       "      <td>0.502485</td>\n",
       "      <td>-0.666659</td>\n",
       "      <td>-1.478034</td>\n",
       "      <td>0.028423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102335</th>\n",
       "      <td>0.413677</td>\n",
       "      <td>-0.306913</td>\n",
       "      <td>-0.639929</td>\n",
       "      <td>-1.882931</td>\n",
       "      <td>-0.649017</td>\n",
       "      <td>0.753651</td>\n",
       "      <td>-0.538778</td>\n",
       "      <td>1.597948</td>\n",
       "      <td>0.380112</td>\n",
       "      <td>-0.405906</td>\n",
       "      <td>-1.153706</td>\n",
       "      <td>0.673933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78411</th>\n",
       "      <td>-0.288804</td>\n",
       "      <td>-0.306913</td>\n",
       "      <td>0.427460</td>\n",
       "      <td>1.085411</td>\n",
       "      <td>1.202343</td>\n",
       "      <td>0.753651</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>-0.661450</td>\n",
       "      <td>-0.505483</td>\n",
       "      <td>-1.070905</td>\n",
       "      <td>1.228568</td>\n",
       "      <td>0.265486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86528</th>\n",
       "      <td>0.645051</td>\n",
       "      <td>-0.306913</td>\n",
       "      <td>0.427460</td>\n",
       "      <td>0.437700</td>\n",
       "      <td>0.263871</td>\n",
       "      <td>0.753651</td>\n",
       "      <td>-0.418634</td>\n",
       "      <td>-0.892381</td>\n",
       "      <td>1.159436</td>\n",
       "      <td>0.475511</td>\n",
       "      <td>-0.041721</td>\n",
       "      <td>0.593745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96230</th>\n",
       "      <td>0.210187</td>\n",
       "      <td>-0.306913</td>\n",
       "      <td>-0.230282</td>\n",
       "      <td>0.159542</td>\n",
       "      <td>0.100055</td>\n",
       "      <td>0.753651</td>\n",
       "      <td>-0.219026</td>\n",
       "      <td>-0.386618</td>\n",
       "      <td>-0.505483</td>\n",
       "      <td>-0.526577</td>\n",
       "      <td>0.510411</td>\n",
       "      <td>1.080646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22800 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        duration_ms  explicit  danceability    energy  loudness      mode  \\\n",
       "113186     1.964016 -0.306913     -1.141890 -0.170274  0.254946  0.753651   \n",
       "42819     -1.241114 -0.306913     -2.284284  1.415226  0.928853  0.753651   \n",
       "59311     -0.133802 -0.306913     -2.272745  0.644332 -0.357281 -1.326874   \n",
       "90417     -0.752701 -0.306913     -0.853406 -1.028589 -1.025040  0.753651   \n",
       "61000      0.076425 -0.306913     -0.068731  1.192700  0.986764 -1.326874   \n",
       "...             ...       ...           ...       ...       ...       ...   \n",
       "83384     -0.132516 -0.306913      1.056354 -0.225905 -0.195250  0.753651   \n",
       "102335     0.413677 -0.306913     -0.639929 -1.882931 -0.649017  0.753651   \n",
       "78411     -0.288804 -0.306913      0.427460  1.085411  1.202343  0.753651   \n",
       "86528      0.645051 -0.306913      0.427460  0.437700  0.263871  0.753651   \n",
       "96230      0.210187 -0.306913     -0.230282  0.159542  0.100055  0.753651   \n",
       "\n",
       "        speechiness  acousticness  instrumentalness  liveness   valence  \\\n",
       "113186    -0.514181     -0.933546         -0.505483 -0.196045 -1.649465   \n",
       "42819      0.314526     -0.933245          2.074015  1.084109 -1.715876   \n",
       "59311      0.560489      0.894329         -0.499332 -0.096361 -1.486915   \n",
       "90417     -0.497153      0.013302         -0.505483 -0.563302 -0.045582   \n",
       "61000     -0.346737      0.506437         -0.505483  0.276143  1.309650   \n",
       "...             ...           ...               ...       ...       ...   \n",
       "83384     -0.486747     -0.902003          0.502485 -0.666659 -1.478034   \n",
       "102335    -0.538778      1.597948          0.380112 -0.405906 -1.153706   \n",
       "78411      0.004233     -0.661450         -0.505483 -1.070905  1.228568   \n",
       "86528     -0.418634     -0.892381          1.159436  0.475511 -0.041721   \n",
       "96230     -0.219026     -0.386618         -0.505483 -0.526577  0.510411   \n",
       "\n",
       "           tempo  \n",
       "113186  0.863697  \n",
       "42819   0.003406  \n",
       "59311  -1.552964  \n",
       "90417  -1.265400  \n",
       "61000  -0.988476  \n",
       "...          ...  \n",
       "83384   0.028423  \n",
       "102335  0.673933  \n",
       "78411   0.265486  \n",
       "86528   0.593745  \n",
       "96230   1.080646  \n",
       "\n",
       "[22800 rows x 12 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artists_0</th>\n",
       "      <th>artists_1</th>\n",
       "      <th>artists_2</th>\n",
       "      <th>artists_3</th>\n",
       "      <th>artists_4</th>\n",
       "      <th>artists_5</th>\n",
       "      <th>artists_6</th>\n",
       "      <th>artists_7</th>\n",
       "      <th>artists_8</th>\n",
       "      <th>artists_9</th>\n",
       "      <th>...</th>\n",
       "      <th>time_signature_3</th>\n",
       "      <th>time_signature_4</th>\n",
       "      <th>time_signature_5</th>\n",
       "      <th>track_genre_0</th>\n",
       "      <th>track_genre_1</th>\n",
       "      <th>track_genre_2</th>\n",
       "      <th>track_genre_3</th>\n",
       "      <th>track_genre_4</th>\n",
       "      <th>track_genre_5</th>\n",
       "      <th>track_genre_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96253</th>\n",
       "      <td>1.138771</td>\n",
       "      <td>-0.804101</td>\n",
       "      <td>1.216131</td>\n",
       "      <td>-0.986895</td>\n",
       "      <td>1.102499</td>\n",
       "      <td>-0.984452</td>\n",
       "      <td>-0.983955</td>\n",
       "      <td>0.987545</td>\n",
       "      <td>1.014391</td>\n",
       "      <td>-1.019343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093954</td>\n",
       "      <td>-0.126795</td>\n",
       "      <td>-0.037636</td>\n",
       "      <td>1.106143</td>\n",
       "      <td>1.111649</td>\n",
       "      <td>-0.899565</td>\n",
       "      <td>-0.981885</td>\n",
       "      <td>-0.982101</td>\n",
       "      <td>-0.998455</td>\n",
       "      <td>1.001679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70417</th>\n",
       "      <td>1.138771</td>\n",
       "      <td>-0.804101</td>\n",
       "      <td>1.216131</td>\n",
       "      <td>-0.986895</td>\n",
       "      <td>-0.907030</td>\n",
       "      <td>-0.984452</td>\n",
       "      <td>1.016306</td>\n",
       "      <td>0.987545</td>\n",
       "      <td>-0.985813</td>\n",
       "      <td>0.981024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093954</td>\n",
       "      <td>-0.126795</td>\n",
       "      <td>-0.037636</td>\n",
       "      <td>1.106143</td>\n",
       "      <td>-0.899565</td>\n",
       "      <td>-0.899565</td>\n",
       "      <td>-0.981885</td>\n",
       "      <td>1.018225</td>\n",
       "      <td>1.001547</td>\n",
       "      <td>1.001679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66688</th>\n",
       "      <td>1.138771</td>\n",
       "      <td>-0.804101</td>\n",
       "      <td>-0.822280</td>\n",
       "      <td>1.013279</td>\n",
       "      <td>1.102499</td>\n",
       "      <td>-0.984452</td>\n",
       "      <td>1.016306</td>\n",
       "      <td>-1.012613</td>\n",
       "      <td>-0.985813</td>\n",
       "      <td>0.981024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093954</td>\n",
       "      <td>-0.126795</td>\n",
       "      <td>-0.037636</td>\n",
       "      <td>1.106143</td>\n",
       "      <td>-0.899565</td>\n",
       "      <td>-0.899565</td>\n",
       "      <td>-0.981885</td>\n",
       "      <td>-0.982101</td>\n",
       "      <td>1.001547</td>\n",
       "      <td>1.001679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51391</th>\n",
       "      <td>1.138771</td>\n",
       "      <td>-0.804101</td>\n",
       "      <td>-0.822280</td>\n",
       "      <td>-0.986895</td>\n",
       "      <td>-0.907030</td>\n",
       "      <td>1.015794</td>\n",
       "      <td>-0.983955</td>\n",
       "      <td>-1.012613</td>\n",
       "      <td>-0.985813</td>\n",
       "      <td>0.981024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093954</td>\n",
       "      <td>-0.126795</td>\n",
       "      <td>-0.037636</td>\n",
       "      <td>-0.904042</td>\n",
       "      <td>1.111649</td>\n",
       "      <td>1.111649</td>\n",
       "      <td>-0.981885</td>\n",
       "      <td>1.018225</td>\n",
       "      <td>-0.998455</td>\n",
       "      <td>-0.998324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95123</th>\n",
       "      <td>1.138771</td>\n",
       "      <td>1.243626</td>\n",
       "      <td>-0.822280</td>\n",
       "      <td>-0.986895</td>\n",
       "      <td>1.102499</td>\n",
       "      <td>1.015794</td>\n",
       "      <td>-0.983955</td>\n",
       "      <td>0.987545</td>\n",
       "      <td>1.014391</td>\n",
       "      <td>-1.019343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093954</td>\n",
       "      <td>-0.126795</td>\n",
       "      <td>-0.037636</td>\n",
       "      <td>1.106143</td>\n",
       "      <td>1.111649</td>\n",
       "      <td>-0.899565</td>\n",
       "      <td>-0.981885</td>\n",
       "      <td>-0.982101</td>\n",
       "      <td>-0.998455</td>\n",
       "      <td>-0.998324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76821</th>\n",
       "      <td>1.138771</td>\n",
       "      <td>-0.804101</td>\n",
       "      <td>1.216131</td>\n",
       "      <td>-0.986895</td>\n",
       "      <td>1.102499</td>\n",
       "      <td>1.015794</td>\n",
       "      <td>-0.983955</td>\n",
       "      <td>-1.012613</td>\n",
       "      <td>-0.985813</td>\n",
       "      <td>0.981024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093954</td>\n",
       "      <td>-0.126795</td>\n",
       "      <td>-0.037636</td>\n",
       "      <td>1.106143</td>\n",
       "      <td>-0.899565</td>\n",
       "      <td>-0.899565</td>\n",
       "      <td>1.018449</td>\n",
       "      <td>1.018225</td>\n",
       "      <td>-0.998455</td>\n",
       "      <td>1.001679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110269</th>\n",
       "      <td>1.138771</td>\n",
       "      <td>1.243626</td>\n",
       "      <td>1.216131</td>\n",
       "      <td>-0.986895</td>\n",
       "      <td>1.102499</td>\n",
       "      <td>-0.984452</td>\n",
       "      <td>1.016306</td>\n",
       "      <td>0.987545</td>\n",
       "      <td>-0.985813</td>\n",
       "      <td>0.981024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093954</td>\n",
       "      <td>-0.126795</td>\n",
       "      <td>-0.037636</td>\n",
       "      <td>1.106143</td>\n",
       "      <td>1.111649</td>\n",
       "      <td>-0.899565</td>\n",
       "      <td>1.018449</td>\n",
       "      <td>1.018225</td>\n",
       "      <td>1.001547</td>\n",
       "      <td>1.001679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103695</th>\n",
       "      <td>1.138771</td>\n",
       "      <td>1.243626</td>\n",
       "      <td>-0.822280</td>\n",
       "      <td>-0.986895</td>\n",
       "      <td>-0.907030</td>\n",
       "      <td>1.015794</td>\n",
       "      <td>-0.983955</td>\n",
       "      <td>-1.012613</td>\n",
       "      <td>1.014391</td>\n",
       "      <td>-1.019343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093954</td>\n",
       "      <td>-0.126795</td>\n",
       "      <td>-0.037636</td>\n",
       "      <td>1.106143</td>\n",
       "      <td>1.111649</td>\n",
       "      <td>-0.899565</td>\n",
       "      <td>1.018449</td>\n",
       "      <td>-0.982101</td>\n",
       "      <td>-0.998455</td>\n",
       "      <td>-0.998324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>-0.878140</td>\n",
       "      <td>-0.804101</td>\n",
       "      <td>-0.822280</td>\n",
       "      <td>-0.986895</td>\n",
       "      <td>-0.907030</td>\n",
       "      <td>-0.984452</td>\n",
       "      <td>-0.983955</td>\n",
       "      <td>-1.012613</td>\n",
       "      <td>1.014391</td>\n",
       "      <td>-1.019343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093954</td>\n",
       "      <td>-0.126795</td>\n",
       "      <td>-0.037636</td>\n",
       "      <td>-0.904042</td>\n",
       "      <td>-0.899565</td>\n",
       "      <td>-0.899565</td>\n",
       "      <td>-0.981885</td>\n",
       "      <td>-0.982101</td>\n",
       "      <td>-0.998455</td>\n",
       "      <td>1.001679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>-0.878140</td>\n",
       "      <td>-0.804101</td>\n",
       "      <td>1.216131</td>\n",
       "      <td>-0.986895</td>\n",
       "      <td>-0.907030</td>\n",
       "      <td>1.015794</td>\n",
       "      <td>-0.983955</td>\n",
       "      <td>0.987545</td>\n",
       "      <td>1.014391</td>\n",
       "      <td>-1.019343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093954</td>\n",
       "      <td>-0.126795</td>\n",
       "      <td>-0.037636</td>\n",
       "      <td>-0.904042</td>\n",
       "      <td>-0.899565</td>\n",
       "      <td>1.111649</td>\n",
       "      <td>-0.981885</td>\n",
       "      <td>-0.982101</td>\n",
       "      <td>-0.998455</td>\n",
       "      <td>-0.998324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91199 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        artists_0  artists_1  artists_2  artists_3  artists_4  artists_5  \\\n",
       "96253    1.138771  -0.804101   1.216131  -0.986895   1.102499  -0.984452   \n",
       "70417    1.138771  -0.804101   1.216131  -0.986895  -0.907030  -0.984452   \n",
       "66688    1.138771  -0.804101  -0.822280   1.013279   1.102499  -0.984452   \n",
       "51391    1.138771  -0.804101  -0.822280  -0.986895  -0.907030   1.015794   \n",
       "95123    1.138771   1.243626  -0.822280  -0.986895   1.102499   1.015794   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "76821    1.138771  -0.804101   1.216131  -0.986895   1.102499   1.015794   \n",
       "110269   1.138771   1.243626   1.216131  -0.986895   1.102499  -0.984452   \n",
       "103695   1.138771   1.243626  -0.822280  -0.986895  -0.907030   1.015794   \n",
       "860     -0.878140  -0.804101  -0.822280  -0.986895  -0.907030  -0.984452   \n",
       "15795   -0.878140  -0.804101   1.216131  -0.986895  -0.907030   1.015794   \n",
       "\n",
       "        artists_6  artists_7  artists_8  artists_9  ...  time_signature_3  \\\n",
       "96253   -0.983955   0.987545   1.014391  -1.019343  ...         -0.093954   \n",
       "70417    1.016306   0.987545  -0.985813   0.981024  ...         -0.093954   \n",
       "66688    1.016306  -1.012613  -0.985813   0.981024  ...         -0.093954   \n",
       "51391   -0.983955  -1.012613  -0.985813   0.981024  ...         -0.093954   \n",
       "95123   -0.983955   0.987545   1.014391  -1.019343  ...         -0.093954   \n",
       "...           ...        ...        ...        ...  ...               ...   \n",
       "76821   -0.983955  -1.012613  -0.985813   0.981024  ...         -0.093954   \n",
       "110269   1.016306   0.987545  -0.985813   0.981024  ...         -0.093954   \n",
       "103695  -0.983955  -1.012613   1.014391  -1.019343  ...         -0.093954   \n",
       "860     -0.983955  -1.012613   1.014391  -1.019343  ...         -0.093954   \n",
       "15795   -0.983955   0.987545   1.014391  -1.019343  ...         -0.093954   \n",
       "\n",
       "        time_signature_4  time_signature_5  track_genre_0  track_genre_1  \\\n",
       "96253          -0.126795         -0.037636       1.106143       1.111649   \n",
       "70417          -0.126795         -0.037636       1.106143      -0.899565   \n",
       "66688          -0.126795         -0.037636       1.106143      -0.899565   \n",
       "51391          -0.126795         -0.037636      -0.904042       1.111649   \n",
       "95123          -0.126795         -0.037636       1.106143       1.111649   \n",
       "...                  ...               ...            ...            ...   \n",
       "76821          -0.126795         -0.037636       1.106143      -0.899565   \n",
       "110269         -0.126795         -0.037636       1.106143       1.111649   \n",
       "103695         -0.126795         -0.037636       1.106143       1.111649   \n",
       "860            -0.126795         -0.037636      -0.904042      -0.899565   \n",
       "15795          -0.126795         -0.037636      -0.904042      -0.899565   \n",
       "\n",
       "        track_genre_2  track_genre_3  track_genre_4  track_genre_5  \\\n",
       "96253       -0.899565      -0.981885      -0.982101      -0.998455   \n",
       "70417       -0.899565      -0.981885       1.018225       1.001547   \n",
       "66688       -0.899565      -0.981885      -0.982101       1.001547   \n",
       "51391        1.111649      -0.981885       1.018225      -0.998455   \n",
       "95123       -0.899565      -0.981885      -0.982101      -0.998455   \n",
       "...               ...            ...            ...            ...   \n",
       "76821       -0.899565       1.018449       1.018225      -0.998455   \n",
       "110269      -0.899565       1.018449       1.018225       1.001547   \n",
       "103695      -0.899565       1.018449      -0.982101      -0.998455   \n",
       "860         -0.899565      -0.981885      -0.982101      -0.998455   \n",
       "15795        1.111649      -0.981885      -0.982101      -0.998455   \n",
       "\n",
       "        track_genre_6  \n",
       "96253        1.001679  \n",
       "70417        1.001679  \n",
       "66688        1.001679  \n",
       "51391       -0.998324  \n",
       "95123       -0.998324  \n",
       "...               ...  \n",
       "76821        1.001679  \n",
       "110269       1.001679  \n",
       "103695      -0.998324  \n",
       "860          1.001679  \n",
       "15795       -0.998324  \n",
       "\n",
       "[91199 rows x 84 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artists_0</th>\n",
       "      <th>artists_1</th>\n",
       "      <th>artists_2</th>\n",
       "      <th>artists_3</th>\n",
       "      <th>artists_4</th>\n",
       "      <th>artists_5</th>\n",
       "      <th>artists_6</th>\n",
       "      <th>artists_7</th>\n",
       "      <th>artists_8</th>\n",
       "      <th>artists_9</th>\n",
       "      <th>...</th>\n",
       "      <th>time_signature_3</th>\n",
       "      <th>time_signature_4</th>\n",
       "      <th>time_signature_5</th>\n",
       "      <th>track_genre_0</th>\n",
       "      <th>track_genre_1</th>\n",
       "      <th>track_genre_2</th>\n",
       "      <th>track_genre_3</th>\n",
       "      <th>track_genre_4</th>\n",
       "      <th>track_genre_5</th>\n",
       "      <th>track_genre_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113186</th>\n",
       "      <td>1.138771</td>\n",
       "      <td>1.243626</td>\n",
       "      <td>1.216131</td>\n",
       "      <td>1.013279</td>\n",
       "      <td>-0.907030</td>\n",
       "      <td>1.015794</td>\n",
       "      <td>-0.983955</td>\n",
       "      <td>-1.012613</td>\n",
       "      <td>-0.985813</td>\n",
       "      <td>-1.019343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093954</td>\n",
       "      <td>-0.126795</td>\n",
       "      <td>-0.037636</td>\n",
       "      <td>1.106143</td>\n",
       "      <td>1.111649</td>\n",
       "      <td>1.111649</td>\n",
       "      <td>-0.981885</td>\n",
       "      <td>-0.982101</td>\n",
       "      <td>1.001547</td>\n",
       "      <td>-0.998324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42819</th>\n",
       "      <td>-0.878140</td>\n",
       "      <td>1.243626</td>\n",
       "      <td>1.216131</td>\n",
       "      <td>1.013279</td>\n",
       "      <td>-0.907030</td>\n",
       "      <td>-0.984452</td>\n",
       "      <td>-0.983955</td>\n",
       "      <td>0.987545</td>\n",
       "      <td>-0.985813</td>\n",
       "      <td>-1.019343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093954</td>\n",
       "      <td>-0.126795</td>\n",
       "      <td>-0.037636</td>\n",
       "      <td>-0.904042</td>\n",
       "      <td>1.111649</td>\n",
       "      <td>-0.899565</td>\n",
       "      <td>1.018449</td>\n",
       "      <td>-0.982101</td>\n",
       "      <td>1.001547</td>\n",
       "      <td>1.001679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59311</th>\n",
       "      <td>1.138771</td>\n",
       "      <td>-0.804101</td>\n",
       "      <td>-0.822280</td>\n",
       "      <td>1.013279</td>\n",
       "      <td>-0.907030</td>\n",
       "      <td>-0.984452</td>\n",
       "      <td>-0.983955</td>\n",
       "      <td>-1.012613</td>\n",
       "      <td>-0.985813</td>\n",
       "      <td>0.981024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093954</td>\n",
       "      <td>-0.126795</td>\n",
       "      <td>-0.037636</td>\n",
       "      <td>-0.904042</td>\n",
       "      <td>1.111649</td>\n",
       "      <td>1.111649</td>\n",
       "      <td>1.018449</td>\n",
       "      <td>1.018225</td>\n",
       "      <td>-0.998455</td>\n",
       "      <td>-0.998324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90417</th>\n",
       "      <td>-0.878140</td>\n",
       "      <td>-0.804101</td>\n",
       "      <td>-0.822280</td>\n",
       "      <td>1.013279</td>\n",
       "      <td>1.102499</td>\n",
       "      <td>-0.984452</td>\n",
       "      <td>1.016306</td>\n",
       "      <td>0.987545</td>\n",
       "      <td>1.014391</td>\n",
       "      <td>0.981024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093954</td>\n",
       "      <td>-0.126795</td>\n",
       "      <td>-0.037636</td>\n",
       "      <td>1.106143</td>\n",
       "      <td>-0.899565</td>\n",
       "      <td>1.111649</td>\n",
       "      <td>1.018449</td>\n",
       "      <td>-0.982101</td>\n",
       "      <td>1.001547</td>\n",
       "      <td>1.001679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61000</th>\n",
       "      <td>1.138771</td>\n",
       "      <td>-0.804101</td>\n",
       "      <td>-0.822280</td>\n",
       "      <td>1.013279</td>\n",
       "      <td>-0.907030</td>\n",
       "      <td>-0.984452</td>\n",
       "      <td>1.016306</td>\n",
       "      <td>-1.012613</td>\n",
       "      <td>1.014391</td>\n",
       "      <td>0.981024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093954</td>\n",
       "      <td>-0.126795</td>\n",
       "      <td>-0.037636</td>\n",
       "      <td>-0.904042</td>\n",
       "      <td>1.111649</td>\n",
       "      <td>1.111649</td>\n",
       "      <td>1.018449</td>\n",
       "      <td>1.018225</td>\n",
       "      <td>1.001547</td>\n",
       "      <td>-0.998324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83384</th>\n",
       "      <td>1.138771</td>\n",
       "      <td>-0.804101</td>\n",
       "      <td>1.216131</td>\n",
       "      <td>1.013279</td>\n",
       "      <td>1.102499</td>\n",
       "      <td>1.015794</td>\n",
       "      <td>1.016306</td>\n",
       "      <td>-1.012613</td>\n",
       "      <td>1.014391</td>\n",
       "      <td>-1.019343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093954</td>\n",
       "      <td>-0.126795</td>\n",
       "      <td>-0.037636</td>\n",
       "      <td>1.106143</td>\n",
       "      <td>-0.899565</td>\n",
       "      <td>1.111649</td>\n",
       "      <td>-0.981885</td>\n",
       "      <td>1.018225</td>\n",
       "      <td>-0.998455</td>\n",
       "      <td>-0.998324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102335</th>\n",
       "      <td>1.138771</td>\n",
       "      <td>1.243626</td>\n",
       "      <td>-0.822280</td>\n",
       "      <td>1.013279</td>\n",
       "      <td>-0.907030</td>\n",
       "      <td>1.015794</td>\n",
       "      <td>1.016306</td>\n",
       "      <td>0.987545</td>\n",
       "      <td>-0.985813</td>\n",
       "      <td>0.981024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093954</td>\n",
       "      <td>-0.126795</td>\n",
       "      <td>-0.037636</td>\n",
       "      <td>1.106143</td>\n",
       "      <td>1.111649</td>\n",
       "      <td>-0.899565</td>\n",
       "      <td>-0.981885</td>\n",
       "      <td>1.018225</td>\n",
       "      <td>1.001547</td>\n",
       "      <td>1.001679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78411</th>\n",
       "      <td>1.138771</td>\n",
       "      <td>-0.804101</td>\n",
       "      <td>1.216131</td>\n",
       "      <td>1.013279</td>\n",
       "      <td>-0.907030</td>\n",
       "      <td>-0.984452</td>\n",
       "      <td>1.016306</td>\n",
       "      <td>0.987545</td>\n",
       "      <td>-0.985813</td>\n",
       "      <td>-1.019343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093954</td>\n",
       "      <td>-0.126795</td>\n",
       "      <td>-0.037636</td>\n",
       "      <td>1.106143</td>\n",
       "      <td>-0.899565</td>\n",
       "      <td>-0.899565</td>\n",
       "      <td>1.018449</td>\n",
       "      <td>1.018225</td>\n",
       "      <td>1.001547</td>\n",
       "      <td>1.001679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86528</th>\n",
       "      <td>-0.878140</td>\n",
       "      <td>-0.804101</td>\n",
       "      <td>-0.822280</td>\n",
       "      <td>-0.986895</td>\n",
       "      <td>-0.907030</td>\n",
       "      <td>1.015794</td>\n",
       "      <td>1.016306</td>\n",
       "      <td>0.987545</td>\n",
       "      <td>1.014391</td>\n",
       "      <td>-1.019343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093954</td>\n",
       "      <td>-0.126795</td>\n",
       "      <td>-0.037636</td>\n",
       "      <td>1.106143</td>\n",
       "      <td>-0.899565</td>\n",
       "      <td>1.111649</td>\n",
       "      <td>-0.981885</td>\n",
       "      <td>1.018225</td>\n",
       "      <td>1.001547</td>\n",
       "      <td>1.001679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96230</th>\n",
       "      <td>-0.878140</td>\n",
       "      <td>1.243626</td>\n",
       "      <td>1.216131</td>\n",
       "      <td>-0.986895</td>\n",
       "      <td>1.102499</td>\n",
       "      <td>1.015794</td>\n",
       "      <td>-0.983955</td>\n",
       "      <td>0.987545</td>\n",
       "      <td>-0.985813</td>\n",
       "      <td>0.981024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093954</td>\n",
       "      <td>-0.126795</td>\n",
       "      <td>-0.037636</td>\n",
       "      <td>1.106143</td>\n",
       "      <td>1.111649</td>\n",
       "      <td>-0.899565</td>\n",
       "      <td>-0.981885</td>\n",
       "      <td>-0.982101</td>\n",
       "      <td>-0.998455</td>\n",
       "      <td>1.001679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22800 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        artists_0  artists_1  artists_2  artists_3  artists_4  artists_5  \\\n",
       "113186   1.138771   1.243626   1.216131   1.013279  -0.907030   1.015794   \n",
       "42819   -0.878140   1.243626   1.216131   1.013279  -0.907030  -0.984452   \n",
       "59311    1.138771  -0.804101  -0.822280   1.013279  -0.907030  -0.984452   \n",
       "90417   -0.878140  -0.804101  -0.822280   1.013279   1.102499  -0.984452   \n",
       "61000    1.138771  -0.804101  -0.822280   1.013279  -0.907030  -0.984452   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "83384    1.138771  -0.804101   1.216131   1.013279   1.102499   1.015794   \n",
       "102335   1.138771   1.243626  -0.822280   1.013279  -0.907030   1.015794   \n",
       "78411    1.138771  -0.804101   1.216131   1.013279  -0.907030  -0.984452   \n",
       "86528   -0.878140  -0.804101  -0.822280  -0.986895  -0.907030   1.015794   \n",
       "96230   -0.878140   1.243626   1.216131  -0.986895   1.102499   1.015794   \n",
       "\n",
       "        artists_6  artists_7  artists_8  artists_9  ...  time_signature_3  \\\n",
       "113186  -0.983955  -1.012613  -0.985813  -1.019343  ...         -0.093954   \n",
       "42819   -0.983955   0.987545  -0.985813  -1.019343  ...         -0.093954   \n",
       "59311   -0.983955  -1.012613  -0.985813   0.981024  ...         -0.093954   \n",
       "90417    1.016306   0.987545   1.014391   0.981024  ...         -0.093954   \n",
       "61000    1.016306  -1.012613   1.014391   0.981024  ...         -0.093954   \n",
       "...           ...        ...        ...        ...  ...               ...   \n",
       "83384    1.016306  -1.012613   1.014391  -1.019343  ...         -0.093954   \n",
       "102335   1.016306   0.987545  -0.985813   0.981024  ...         -0.093954   \n",
       "78411    1.016306   0.987545  -0.985813  -1.019343  ...         -0.093954   \n",
       "86528    1.016306   0.987545   1.014391  -1.019343  ...         -0.093954   \n",
       "96230   -0.983955   0.987545  -0.985813   0.981024  ...         -0.093954   \n",
       "\n",
       "        time_signature_4  time_signature_5  track_genre_0  track_genre_1  \\\n",
       "113186         -0.126795         -0.037636       1.106143       1.111649   \n",
       "42819          -0.126795         -0.037636      -0.904042       1.111649   \n",
       "59311          -0.126795         -0.037636      -0.904042       1.111649   \n",
       "90417          -0.126795         -0.037636       1.106143      -0.899565   \n",
       "61000          -0.126795         -0.037636      -0.904042       1.111649   \n",
       "...                  ...               ...            ...            ...   \n",
       "83384          -0.126795         -0.037636       1.106143      -0.899565   \n",
       "102335         -0.126795         -0.037636       1.106143       1.111649   \n",
       "78411          -0.126795         -0.037636       1.106143      -0.899565   \n",
       "86528          -0.126795         -0.037636       1.106143      -0.899565   \n",
       "96230          -0.126795         -0.037636       1.106143       1.111649   \n",
       "\n",
       "        track_genre_2  track_genre_3  track_genre_4  track_genre_5  \\\n",
       "113186       1.111649      -0.981885      -0.982101       1.001547   \n",
       "42819       -0.899565       1.018449      -0.982101       1.001547   \n",
       "59311        1.111649       1.018449       1.018225      -0.998455   \n",
       "90417        1.111649       1.018449      -0.982101       1.001547   \n",
       "61000        1.111649       1.018449       1.018225       1.001547   \n",
       "...               ...            ...            ...            ...   \n",
       "83384        1.111649      -0.981885       1.018225      -0.998455   \n",
       "102335      -0.899565      -0.981885       1.018225       1.001547   \n",
       "78411       -0.899565       1.018449       1.018225       1.001547   \n",
       "86528        1.111649      -0.981885       1.018225       1.001547   \n",
       "96230       -0.899565      -0.981885      -0.982101      -0.998455   \n",
       "\n",
       "        track_genre_6  \n",
       "113186      -0.998324  \n",
       "42819        1.001679  \n",
       "59311       -0.998324  \n",
       "90417        1.001679  \n",
       "61000       -0.998324  \n",
       "...               ...  \n",
       "83384       -0.998324  \n",
       "102335       1.001679  \n",
       "78411        1.001679  \n",
       "86528        1.001679  \n",
       "96230        1.001679  \n",
       "\n",
       "[22800 rows x 84 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96253     41\n",
       "70417     52\n",
       "66688     11\n",
       "51391     61\n",
       "95123     37\n",
       "          ..\n",
       "76821     20\n",
       "110269    28\n",
       "103695     0\n",
       "860       44\n",
       "15795     55\n",
       "Name: popularity, Length: 91199, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113186    50\n",
       "42819     11\n",
       "59311      0\n",
       "90417     34\n",
       "61000     57\n",
       "          ..\n",
       "83384     59\n",
       "102335     0\n",
       "78411     29\n",
       "86528     42\n",
       "96230     42\n",
       "Name: popularity, Length: 22800, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ridge Regression implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeRegression:\n",
    "\n",
    "    def __init__(self, alpha = 1.0):\n",
    "        self._alpha = alpha\n",
    "        self._w = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        _X = X.copy()\n",
    "        _X.insert(0, 'dummy_feature', 1)\n",
    "\n",
    "        I = np.identity(_X.shape[1])\n",
    "        I[0][0] = 0                         # justify this line\n",
    "\n",
    "        self._w = np.linalg.inv(_X.T @ _X + self._alpha * I) @ _X.T @ y\n",
    "        self._w.index = _X.columns\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        if self._w is None:\n",
    "            raise RuntimeError('Model is still to fit')\n",
    "        \n",
    "        _X = X.copy()\n",
    "        _X.insert(0, 'dummy_feature', 1)\n",
    "        \n",
    "        y_prediction = _X @ self._w\n",
    "        \n",
    "        return y_prediction\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {\"alpha\": self._alpha}\n",
    "    \"\"\"\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeRegression2:\n",
    "\n",
    "    def __init__(self, alpha = 1.0):\n",
    "        self._alpha = alpha\n",
    "        self._w = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        #X_copy = X.copy(deep=False)\n",
    "\n",
    "        X.insert(0, 'dummy_feature', 1)\n",
    "\n",
    "        I = np.identity(X.shape[1])\n",
    "        I[0][0] = 0                         # justify this line\n",
    "\n",
    "        self._w = np.linalg.inv(X.T @ X + self._alpha * I) @ X.T @ y\n",
    "        self._w.index = X.columns\n",
    "\n",
    "        X.drop(columns='dummy_feature', inplace=True)\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        if self._w is None:\n",
    "            raise RuntimeError('Model is still to fit')\n",
    "        \n",
    "        #X_copy = X.copy(deep=False)\n",
    "\n",
    "        X.insert(0, 'dummy_feature', 1)\n",
    "        \n",
    "        y_prediction = X @ self._w\n",
    "\n",
    "        X.drop(columns='dummy_feature', inplace=True)\n",
    "        \n",
    "        return y_prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ridge Regression test considering only numerical features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m y \u001b[39m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m alpha \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39mlinspace(\u001b[39m0.0\u001b[39m, \u001b[39m400.0\u001b[39m, num\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, endpoint\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m----> 5\u001b[0m     scores \u001b[39m=\u001b[39m cross_val_score(RidgeRegression(alpha), \n\u001b[1;32m      6\u001b[0m                              X_train_numerical, \n\u001b[1;32m      7\u001b[0m                              y_train, \n\u001b[1;32m      8\u001b[0m                              scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mneg_mean_squared_error\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m      9\u001b[0m                              cv\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[1;32m     10\u001b[0m     x\u001b[39m.\u001b[39mappend(alpha)\n\u001b[1;32m     11\u001b[0m     y\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39mmean(scores))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    560\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m--> 562\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m    563\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    564\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    565\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    566\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    567\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[1;32m    568\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m    569\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    570\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    571\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[1;32m    572\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[1;32m    573\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    574\u001b[0m )\n\u001b[1;32m    575\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 309\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    310\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    311\u001b[0m         clone(estimator),\n\u001b[1;32m    312\u001b[0m         X,\n\u001b[1;32m    313\u001b[0m         y,\n\u001b[1;32m    314\u001b[0m         scorers,\n\u001b[1;32m    315\u001b[0m         train,\n\u001b[1;32m    316\u001b[0m         test,\n\u001b[1;32m    317\u001b[0m         verbose,\n\u001b[1;32m    318\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    319\u001b[0m         fit_params,\n\u001b[1;32m    320\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    321\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    322\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    323\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    324\u001b[0m     )\n\u001b[1;32m    325\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m indices\n\u001b[1;32m    326\u001b[0m )\n\u001b[1;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    330\u001b[0m \u001b[39m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1855\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1853\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1854\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1855\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[1;32m   1857\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1858\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1859\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1784\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1782\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1783\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1784\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1785\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1786\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:754\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    751\u001b[0m result[\u001b[39m\"\u001b[39m\u001b[39mfit_error\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    753\u001b[0m fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n\u001b[0;32m--> 754\u001b[0m test_scores \u001b[39m=\u001b[39m _score(estimator, X_test, y_test, scorer, error_score)\n\u001b[1;32m    755\u001b[0m score_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time \u001b[39m-\u001b[39m fit_time\n\u001b[1;32m    756\u001b[0m \u001b[39mif\u001b[39;00m return_train_score:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:813\u001b[0m, in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[1;32m    811\u001b[0m         scores \u001b[39m=\u001b[39m scorer(estimator, X_test)\n\u001b[1;32m    812\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 813\u001b[0m         scores \u001b[39m=\u001b[39m scorer(estimator, X_test, y_test)\n\u001b[1;32m    814\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    815\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[1;32m    816\u001b[0m         \u001b[39m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[1;32m    817\u001b[0m         \u001b[39m# parameter is equal to \"raise\".\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py:136\u001b[0m, in \u001b[0;36m_MultimetricScorer.__call__\u001b[0;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(scorer, _BaseScorer):\n\u001b[0;32m--> 136\u001b[0m         score \u001b[39m=\u001b[39m scorer\u001b[39m.\u001b[39;49m_score(\n\u001b[1;32m    137\u001b[0m             cached_call, estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mrouted_params\u001b[39m.\u001b[39;49mget(name)\u001b[39m.\u001b[39;49mscore\n\u001b[1;32m    138\u001b[0m         )\n\u001b[1;32m    139\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m         score \u001b[39m=\u001b[39m scorer(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mrouted_params\u001b[39m.\u001b[39mget(name)\u001b[39m.\u001b[39mscore)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py:353\u001b[0m, in \u001b[0;36m_PredictScorer._score\u001b[0;34m(self, method_caller, estimator, X, y_true, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Evaluate predicted target values for X relative to y_true.\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \n\u001b[1;32m    318\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[39m    Score function applied to prediction of estimator on X.\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warn_overlap(\n\u001b[1;32m    346\u001b[0m     message\u001b[39m=\u001b[39m(\n\u001b[1;32m    347\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThere is an overlap between set kwargs of this scorer instance and\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    351\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m    352\u001b[0m )\n\u001b[0;32m--> 353\u001b[0m y_pred \u001b[39m=\u001b[39m method_caller(estimator, \u001b[39m\"\u001b[39;49m\u001b[39mpredict\u001b[39;49m\u001b[39m\"\u001b[39;49m, X)\n\u001b[1;32m    354\u001b[0m scoring_kwargs \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_kwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs}\n\u001b[1;32m    355\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sign \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_score_func(y_true, y_pred, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mscoring_kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py:86\u001b[0m, in \u001b[0;36m_cached_call\u001b[0;34m(cache, estimator, response_method, *args, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39mif\u001b[39;00m cache \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m response_method \u001b[39min\u001b[39;00m cache:\n\u001b[1;32m     84\u001b[0m     \u001b[39mreturn\u001b[39;00m cache[response_method]\n\u001b[0;32m---> 86\u001b[0m result, _ \u001b[39m=\u001b[39m _get_response_values(\n\u001b[1;32m     87\u001b[0m     estimator, \u001b[39m*\u001b[39;49margs, response_method\u001b[39m=\u001b[39;49mresponse_method, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m     88\u001b[0m )\n\u001b[1;32m     90\u001b[0m \u001b[39mif\u001b[39;00m cache \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     cache[response_method] \u001b[39m=\u001b[39m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_response.py:109\u001b[0m, in \u001b[0;36m_get_response_values\u001b[0;34m(estimator, X, response_method, pos_label)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[39mif\u001b[39;00m response_method \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpredict\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    103\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    104\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m should either be a classifier to be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mused with response_method=\u001b[39m\u001b[39m{\u001b[39;00mresponse_method\u001b[39m}\u001b[39;00m\u001b[39m or the response_method \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mshould be \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpredict\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. Got a regressor with response_method=\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mresponse_method\u001b[39m}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m         )\n\u001b[0;32m--> 109\u001b[0m     y_pred, pos_label \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39;49mpredict(X), \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[39mreturn\u001b[39;00m y_pred, pos_label\n",
      "Cell \u001b[0;32mIn[56], line 27\u001b[0m, in \u001b[0;36mRidgeRegression.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     24\u001b[0m _X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m     25\u001b[0m _X\u001b[39m.\u001b[39minsert(\u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdummy_feature\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m y_prediction \u001b[39m=\u001b[39m _X \u001b[39m@\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_w\n\u001b[1;32m     29\u001b[0m \u001b[39mreturn\u001b[39;00m y_prediction\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:1630\u001b[0m, in \u001b[0;36mDataFrame.__matmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1626\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__matmul__\u001b[39m(\u001b[39mself\u001b[39m, other: AnyArrayLike \u001b[39m|\u001b[39m DataFrame) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   1627\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m \u001b[39m    Matrix multiplication using binary `@` operator in Python>=3.5.\u001b[39;00m\n\u001b[1;32m   1629\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1630\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdot(other)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:1587\u001b[0m, in \u001b[0;36mDataFrame.dot\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1585\u001b[0m     left \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreindex(columns\u001b[39m=\u001b[39mcommon, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1586\u001b[0m     right \u001b[39m=\u001b[39m other\u001b[39m.\u001b[39mreindex(index\u001b[39m=\u001b[39mcommon, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m-> 1587\u001b[0m     lvals \u001b[39m=\u001b[39m left\u001b[39m.\u001b[39;49mvalues\n\u001b[1;32m   1588\u001b[0m     rvals \u001b[39m=\u001b[39m right\u001b[39m.\u001b[39m_values\n\u001b[1;32m   1589\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:11360\u001b[0m, in \u001b[0;36mDataFrame.values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m  11286\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m  11287\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalues\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m  11288\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m  11289\u001b[0m \u001b[39m    Return a Numpy representation of the DataFrame.\u001b[39;00m\n\u001b[1;32m  11290\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11358\u001b[0m \u001b[39m           ['monkey', nan, None]], dtype=object)\u001b[39;00m\n\u001b[1;32m  11359\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m> 11360\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mas_array()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:1732\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1730\u001b[0m         arr\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mwriteable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1732\u001b[0m     arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interleave(dtype\u001b[39m=\u001b[39;49mdtype, na_value\u001b[39m=\u001b[39;49mna_value)\n\u001b[1;32m   1733\u001b[0m     \u001b[39m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[1;32m   1734\u001b[0m     \u001b[39m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[1;32m   1736\u001b[0m \u001b[39mif\u001b[39;00m na_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m lib\u001b[39m.\u001b[39mno_default:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:1754\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[39mReturn ndarray from blocks with specified item order\u001b[39;00m\n\u001b[1;32m   1748\u001b[0m \u001b[39mItems must be contained in the blocks\u001b[39;00m\n\u001b[1;32m   1749\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m dtype:\n\u001b[1;32m   1751\u001b[0m     \u001b[39m# Incompatible types in assignment (expression has type\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m     \u001b[39m# \"Optional[Union[dtype[Any], ExtensionDtype]]\", variable has\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m     \u001b[39m# type \"Optional[dtype[Any]]\")\u001b[39;00m\n\u001b[0;32m-> 1754\u001b[0m     dtype \u001b[39m=\u001b[39m interleaved_dtype(  \u001b[39m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[1;32m   1755\u001b[0m         [blk\u001b[39m.\u001b[39;49mdtype \u001b[39mfor\u001b[39;49;00m blk \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblocks]\n\u001b[1;32m   1756\u001b[0m     )\n\u001b[1;32m   1758\u001b[0m \u001b[39m# TODO: https://github.com/pandas-dev/pandas/issues/22791\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[39m# Give EAs some input on what happens here. Sparse needs this.\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, SparseDtype):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/base.py:224\u001b[0m, in \u001b[0;36minterleaved_dtype\u001b[0;34m(dtypes)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(dtypes):\n\u001b[1;32m    222\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m \u001b[39mreturn\u001b[39;00m find_common_type(dtypes)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/dtypes/cast.py:1466\u001b[0m, in \u001b[0;36mfind_common_type\u001b[0;34m(types)\u001b[0m\n\u001b[1;32m   1463\u001b[0m         \u001b[39mif\u001b[39;00m is_integer_dtype(t) \u001b[39mor\u001b[39;00m is_float_dtype(t) \u001b[39mor\u001b[39;00m is_complex_dtype(t):\n\u001b[1;32m   1464\u001b[0m             \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1466\u001b[0m \u001b[39mreturn\u001b[39;00m np_find_common_type(\u001b[39m*\u001b[39;49mtypes)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/dtypes/cast.py:1387\u001b[0m, in \u001b[0;36mnp_find_common_type\u001b[0;34m(*dtypes)\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m \u001b[39mnp.find_common_type implementation pre-1.25 deprecation using np.result_type\u001b[39;00m\n\u001b[1;32m   1376\u001b[0m \u001b[39mhttps://github.com/pandas-dev/pandas/pull/49569#issuecomment-1308300065\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1384\u001b[0m \u001b[39mnp.dtype\u001b[39;00m\n\u001b[1;32m   1385\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1386\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1387\u001b[0m     common_dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mresult_type(\u001b[39m*\u001b[39;49mdtypes)\n\u001b[1;32m   1388\u001b[0m     \u001b[39mif\u001b[39;00m common_dtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmMSU\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1389\u001b[0m         \u001b[39m# NumPy promotion currently (1.25) misbehaves for for times and strings,\u001b[39;00m\n\u001b[1;32m   1390\u001b[0m         \u001b[39m# so fall back to object (find_common_dtype did unless there\u001b[39;00m\n\u001b[1;32m   1391\u001b[0m         \u001b[39m# was only one dtype)\u001b[39;00m\n\u001b[1;32m   1392\u001b[0m         common_dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mO\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mresult_type\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for alpha in np.linspace(0.0, 400.0, num=10, endpoint=False):\n",
    "    scores = cross_val_score(RidgeRegression(alpha), \n",
    "                             X_train_numerical, \n",
    "                             y_train, \n",
    "                             scoring='neg_mean_squared_error', \n",
    "                             cv=5)\n",
    "    x.append(alpha)\n",
    "    y.append(np.mean(scores))\n",
    "\n",
    "best_lambda = x[y.index(max(y))]\n",
    "best_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y)\n",
    "\n",
    "ax.set(xlabel='alpha', ylabel='neg_mean_squared_error',\n",
    "       title='plot1')\n",
    "ax.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "485.58364614571894\n"
     ]
    }
   ],
   "source": [
    "rr = RidgeRegression(best_lambda)\n",
    "rr.fit(X_train_numerical, y_train)\n",
    "y_prediction = rr.predict(X_test_numerical)\n",
    "\n",
    "print(mean_squared_error(y_prediction, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "485.5765552369795\n"
     ]
    }
   ],
   "source": [
    "learner = GridSearchCV(estimator=Ridge(), \n",
    "                       param_grid={'alpha': np.linspace(0.0, 400.0, num=10, endpoint=False)}, \n",
    "                       cv=5, \n",
    "                       scoring='neg_mean_squared_error', \n",
    "                       return_train_score=True)\n",
    "learner.fit(X_train_numerical, y_train)\n",
    "\n",
    "learner.best_estimator_.fit(X_train_numerical, y_train)\n",
    "y_prediction = learner.best_estimator_.predict(X_test_numerical)\n",
    "\n",
    "print(mean_squared_error(y_prediction, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ridge Regression test considering both numerical and categorical features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for alpha in np.linspace(0.0, 200.0, num=40, endpoint=False):\n",
    "    scores = cross_val_score(RidgeRegression(alpha), \n",
    "                             X_train, \n",
    "                             y_train, \n",
    "                             scoring='neg_mean_squared_error', \n",
    "                             cv=5)\n",
    "    x.append(alpha)\n",
    "    y.append(np.mean(scores))\n",
    "\n",
    "best_lambda = x[y.index(max(y))]\n",
    "best_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y)\n",
    "\n",
    "ax.set(xlabel='alpha', ylabel='neg_mean_squared_error',\n",
    "       title='plot2')\n",
    "ax.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404.7893600359107\n"
     ]
    }
   ],
   "source": [
    "rr = RidgeRegression(best_lambda)\n",
    "rr.fit(X_train, y_train)\n",
    "y_prediction = rr.predict(X_test)\n",
    "\n",
    "print(mean_squared_error(y_prediction, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m learner \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mRidge(), \n\u001b[1;32m      2\u001b[0m                        param_grid\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39malpha\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mlinspace(\u001b[39m0.0\u001b[39m, \u001b[39m200.0\u001b[39m, num\u001b[39m=\u001b[39m\u001b[39m40\u001b[39m, endpoint\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)}, \n\u001b[1;32m      3\u001b[0m                        cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, \n\u001b[1;32m      4\u001b[0m                        scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mneg_mean_squared_error\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m      5\u001b[0m                        return_train_score\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> 6\u001b[0m learner\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m      8\u001b[0m learner\u001b[39m.\u001b[39mbest_estimator_\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m      9\u001b[0m y_prediction \u001b[39m=\u001b[39m learner\u001b[39m.\u001b[39mbest_estimator_\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1418\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m         clone(base_estimator),\n\u001b[1;32m    848\u001b[0m         X,\n\u001b[1;32m    849\u001b[0m         y,\n\u001b[1;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    856\u001b[0m     )\n\u001b[1;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    859\u001b[0m     )\n\u001b[1;32m    860\u001b[0m )\n\u001b[1;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1855\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1853\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1854\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1855\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[1;32m   1857\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1858\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1859\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1784\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1782\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1783\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1784\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1785\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1786\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    730\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    731\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 732\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    734\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    735\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    736\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:1142\u001b[0m, in \u001b[0;36mRidge.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1133\u001b[0m _accept_sparse \u001b[39m=\u001b[39m _get_valid_accept_sparse(sparse\u001b[39m.\u001b[39missparse(X), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msolver)\n\u001b[1;32m   1134\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[1;32m   1135\u001b[0m     X,\n\u001b[1;32m   1136\u001b[0m     y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1140\u001b[0m     y_numeric\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   1141\u001b[0m )\n\u001b[0;32m-> 1142\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49msample_weight)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:894\u001b[0m, in \u001b[0;36m_BaseRidge.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m         \u001b[39m# for dense matrices or when intercept is set to 0\u001b[39;00m\n\u001b[1;32m    892\u001b[0m         params \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 894\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m _ridge_regression(\n\u001b[1;32m    895\u001b[0m         X,\n\u001b[1;32m    896\u001b[0m         y,\n\u001b[1;32m    897\u001b[0m         alpha\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malpha,\n\u001b[1;32m    898\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    899\u001b[0m         max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m    900\u001b[0m         tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[1;32m    901\u001b[0m         solver\u001b[39m=\u001b[39;49msolver,\n\u001b[1;32m    902\u001b[0m         positive\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpositive,\n\u001b[1;32m    903\u001b[0m         random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[1;32m    904\u001b[0m         return_n_iter\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    905\u001b[0m         return_intercept\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    906\u001b[0m         check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    907\u001b[0m         fit_intercept\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[1;32m    908\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams,\n\u001b[1;32m    909\u001b[0m     )\n\u001b[1;32m    910\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_intercept(X_offset, y_offset, X_scale)\n\u001b[1;32m    912\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:763\u001b[0m, in \u001b[0;36m_ridge_regression\u001b[0;34m(X, y, alpha, sample_weight, solver, max_iter, tol, verbose, positive, random_state, return_n_iter, return_intercept, X_scale, X_offset, check_input, fit_intercept)\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[39mif\u001b[39;00m sparse\u001b[39m.\u001b[39missparse(X):\n\u001b[1;32m    762\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mSVD solver does not support sparse inputs currently\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 763\u001b[0m     coef \u001b[39m=\u001b[39m _solve_svd(X, y, alpha)\n\u001b[1;32m    765\u001b[0m \u001b[39mif\u001b[39;00m ravel:\n\u001b[1;32m    766\u001b[0m     \u001b[39m# When y was passed as a 1d-array, we flatten the coefficients.\u001b[39;00m\n\u001b[1;32m    767\u001b[0m     coef \u001b[39m=\u001b[39m coef\u001b[39m.\u001b[39mravel()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:284\u001b[0m, in \u001b[0;36m_solve_svd\u001b[0;34m(X, y, alpha)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_solve_svd\u001b[39m(X, y, alpha):\n\u001b[0;32m--> 284\u001b[0m     U, s, Vt \u001b[39m=\u001b[39m linalg\u001b[39m.\u001b[39;49msvd(X, full_matrices\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    285\u001b[0m     idx \u001b[39m=\u001b[39m s \u001b[39m>\u001b[39m \u001b[39m1e-15\u001b[39m  \u001b[39m# same default value as scipy.linalg.pinv\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     s_nnz \u001b[39m=\u001b[39m s[idx][:, np\u001b[39m.\u001b[39mnewaxis]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/linalg/_decomp_svd.py:127\u001b[0m, in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, overwrite_a, check_finite, lapack_driver)\u001b[0m\n\u001b[1;32m    123\u001b[0m lwork \u001b[39m=\u001b[39m _compute_lwork(gesXd_lwork, a1\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], a1\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],\n\u001b[1;32m    124\u001b[0m                        compute_uv\u001b[39m=\u001b[39mcompute_uv, full_matrices\u001b[39m=\u001b[39mfull_matrices)\n\u001b[1;32m    126\u001b[0m \u001b[39m# perform decomposition\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m u, s, v, info \u001b[39m=\u001b[39m gesXd(a1, compute_uv\u001b[39m=\u001b[39;49mcompute_uv, lwork\u001b[39m=\u001b[39;49mlwork,\n\u001b[1;32m    128\u001b[0m                       full_matrices\u001b[39m=\u001b[39;49mfull_matrices, overwrite_a\u001b[39m=\u001b[39;49moverwrite_a)\n\u001b[1;32m    130\u001b[0m \u001b[39mif\u001b[39;00m info \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    131\u001b[0m     \u001b[39mraise\u001b[39;00m LinAlgError(\u001b[39m\"\u001b[39m\u001b[39mSVD did not converge\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learner = GridSearchCV(estimator=Ridge(), \n",
    "                       param_grid={'alpha': np.linspace(0.0, 200.0, num=40, endpoint=False)}, \n",
    "                       cv=5, \n",
    "                       scoring='neg_mean_squared_error', \n",
    "                       return_train_score=True)\n",
    "learner.fit(X_train, y_train)\n",
    "\n",
    "learner.best_estimator_.fit(X_train, y_train)\n",
    "y_prediction = learner.best_estimator_.predict(X_test)\n",
    "\n",
    "print(learner.best_params_)\n",
    "print(mean_squared_error(y_prediction, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Kernel Ridge Regression implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelRidgeRegression:\n",
    "\n",
    "    def __init__(self, α = 1.0, γ = 1.0):\n",
    "\n",
    "        if α < 0: raise ValueError(\"α must be >= 0\")\n",
    "        if γ <= 0: raise ValueError(\"γ must be > 0\")\n",
    "        self._α = α\n",
    "        self._γ = γ\n",
    "\n",
    "        self._constant_term = None \n",
    "        self._x_i = None\n",
    "\n",
    "    def gaussian_kernel(self, x_i, x_j):\n",
    "        return np.exp(np.linalg.norm(x_i - x_j) / (-2 * self._γ))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "\n",
    "        _X = X.copy()\n",
    "        _X.insert(0, 'dummy_feature', 1)\n",
    "\n",
    "        m = _X.shape[0]\n",
    "\n",
    "        K = np.zeros((m, m))\n",
    "        for i in range(m):\n",
    "            for j in range(i, m):\n",
    "                K[i][j] = self.gaussian_kernel(_X.iloc[i], _X.iloc[j])\n",
    "                K[j][i] = K[i][j]\n",
    "        \n",
    "        I = np.identity(_X.shape[0])\n",
    "        I[0][0] = 0                         # justify this line\n",
    "\n",
    "        self._constant_term = y.T @ np.linalg.inv(K + self._α * I)\n",
    "        self._x_i = _X\n",
    "    \n",
    "    def predict(self, X):\n",
    "\n",
    "        if self._constant_term is None or self._x_i is None:\n",
    "            raise RuntimeError('Model is still to fit')\n",
    "        \n",
    "        _X = X.copy()\n",
    "        _X.insert(0, 'dummy_feature', 1)\n",
    "\n",
    "        y_prediction = np.zeros(_X.shape[0])\n",
    "\n",
    "        for i in range(len(y_prediction)):\n",
    "            k_x = [self.gaussian_kernel(row, _X.iloc[i]) for _, row in self._x_i.iterrows()]\n",
    "            y_prediction[i] = self._constant_term @ k_x\n",
    "\n",
    "        return y_prediction\n",
    "    \n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {\"α\": self._α, \"γ\": self._γ}\n",
    "    \"\"\"\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelRidgeRegression2:\n",
    "\n",
    "    def __init__(self, α = 1.0, γ = 1.0):\n",
    "\n",
    "        if α < 0: raise ValueError(\"α must be >= 0\")\n",
    "        if γ <= 0: raise ValueError(\"γ must be > 0\")\n",
    "        self._α = α\n",
    "        self._γ = γ\n",
    "\n",
    "        self._constant_term = None \n",
    "        self._x_i = None\n",
    "\n",
    "    def gaussian_kernel(self, x_i, x_j):\n",
    "        return np.exp(np.linalg.norm(x_i - x_j) / (-2 * self._γ))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "\n",
    "        #_X = X.copy()\n",
    "        #_X.insert(0, 'dummy_feature', 1)\n",
    "\n",
    "        m = X.shape[0]\n",
    "\n",
    "        _X = np.insert(X, 0, np.ones(m), axis=1)\n",
    "\n",
    "        print(_X)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        K = np.zeros((m, m))\n",
    "        for i in range(m):\n",
    "            for j in range(i, m):\n",
    "                K[i][j] = self.gaussian_kernel(_X.iloc[i], _X.iloc[j])\n",
    "                K[j][i] = K[i][j]\n",
    "        \n",
    "        I = np.identity(_X.shape[0])\n",
    "        I[0][0] = 0                         # justify this line\n",
    "\n",
    "        self._constant_term = y.T @ np.linalg.inv(K + self._α * I)\n",
    "        self._x_i = _X\n",
    "    \n",
    "    def predict(self, X):\n",
    "\n",
    "        if self._constant_term is None or self._x_i is None:\n",
    "            raise RuntimeError('Model is still to fit')\n",
    "        \n",
    "        _X = X.copy()\n",
    "        _X.insert(0, 'dummy_feature', 1)\n",
    "\n",
    "        y_prediction = np.zeros(_X.shape[0])\n",
    "\n",
    "        for i in range(len(y_prediction)):\n",
    "            k_x = [self.gaussian_kernel(row, _X.iloc[i]) for _, row in self._x_i.iterrows()]\n",
    "            y_prediction[i] = self._constant_term @ k_x\n",
    "\n",
    "        return y_prediction\n",
    "    \n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {\"α\": self._α, \"γ\": self._γ}\n",
    "    \"\"\"\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_numerical_reduced = X_train_numerical.sample(n=300, random_state=1)\n",
    "y_train_reduced = pd.Series( data = [y_train[i] for i, _ in X_train_numerical_reduced.iterrows()], \n",
    "                            index = [i for i, _ in X_train_numerical_reduced.iterrows()])\n",
    "\n",
    "X_test_numerical_reduced = X_test_numerical.sample(n=100, random_state=1)\n",
    "y_test_reduced = pd.Series( data = [y_test[i] for i, _ in X_test_numerical_reduced.iterrows()], \n",
    "                           index = [i for i, _ in X_test_numerical_reduced.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -0.9073335  -0.30691273 ... -0.67347962 -1.36606374\n",
      "  -0.90285045]\n",
      " [ 1.         -0.41631037 -0.30691273 ...  0.76407055  1.7652549\n",
      "   0.71275969]\n",
      " [ 1.          0.35530535 -0.30691273 ...  0.07677466 -0.200024\n",
      "   0.32659434]\n",
      " ...\n",
      " [ 1.          0.38369039 -0.30691273 ... -0.24326388  1.41389855\n",
      "  -0.68930372]\n",
      " [ 1.         -0.89769906  3.25825524 ... -0.43213908  1.04709797\n",
      "  -0.67189175]\n",
      " [ 1.         -0.47338585 -0.30691273 ... -0.55805589 -0.75601646\n",
      "  -0.53206234]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m rr \u001b[39m=\u001b[39m KernelRidgeRegression2()\n\u001b[0;32m----> 2\u001b[0m rr\u001b[39m.\u001b[39;49mfit(X_train_numerical_reduced\u001b[39m.\u001b[39;49mvalues, y_train_reduced\u001b[39m.\u001b[39;49mvalues)\n",
      "Cell \u001b[0;32mIn[110], line 34\u001b[0m, in \u001b[0;36mKernelRidgeRegression2.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(m):\n\u001b[1;32m     33\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(i, m):\n\u001b[0;32m---> 34\u001b[0m         K[i][j] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgaussian_kernel(_X\u001b[39m.\u001b[39;49miloc[i], _X\u001b[39m.\u001b[39miloc[j])\n\u001b[1;32m     35\u001b[0m         K[j][i] \u001b[39m=\u001b[39m K[i][j]\n\u001b[1;32m     37\u001b[0m I \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39midentity(_X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "rr = KernelRidgeRegression2()\n",
    "rr.fit(X_train_numerical_reduced.values, y_train_reduced.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.9073335 , -0.30691273,  0.36399364, ..., -0.67347962,\n",
       "        -1.36606374, -0.90285045],\n",
       "       [-0.41631037, -0.30691273, -0.32836649, ...,  0.76407055,\n",
       "         1.7652549 ,  0.71275969],\n",
       "       [ 0.35530535, -0.30691273, -0.41491151, ...,  0.07677466,\n",
       "        -0.200024  ,  0.32659434],\n",
       "       ...,\n",
       "       [ 0.38369039, -0.30691273,  0.88326375, ..., -0.24326388,\n",
       "         1.41389855, -0.68930372],\n",
       "       [-0.89769906,  3.25825524,  1.92180395, ..., -0.43213908,\n",
       "         1.04709797, -0.67189175],\n",
       "       [-0.47338585, -0.30691273,  1.1775168 , ..., -0.55805589,\n",
       "        -0.75601646, -0.53206234]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = rr.predict(pd.DataFrame(X_test_numerical_reduced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540.0942602861622\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(y_prediction, y_test_reduced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43476    15.551067\n",
       "50436    -3.626715\n",
       "43867   -20.563564\n",
       "27688     8.917089\n",
       "62857   -11.063682\n",
       "           ...    \n",
       "61825    12.224850\n",
       "49006   -26.267448\n",
       "91042    37.986883\n",
       "34829    -3.645929\n",
       "25043   -15.619700\n",
       "Length: 100, dtype: float64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prediction - y_test_reduced"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
